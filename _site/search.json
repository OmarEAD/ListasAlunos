[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Observe as imagens abaixo e tente tirar o máximo e conclusões possíveis.\n\n\n\nA imagem foi feita pelo autor do site.\nO local é a saida de um supermercado de Maringá.\nEra um domingo de manhã, aproximadamente 10h30.\nFoi uma grande emoção fazer esta imagem. Observa que ela esta tremida.\n\n\n\n\n\nO sujeito tem aproximadamente quantos anos?\nHá uma criança subentendida no cenário. O sujeito é o pai, ou o avô, ou o tio dela (ou outra coisa)?\nE a mãe da criança? Por que não é ela que veio ao supermercado?\nEle foi comprar cerveja ou fraudas?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#análise-bivariada",
    "href": "index.html#análise-bivariada",
    "title": "Lista de exercícios",
    "section": "Análise bivariada",
    "text": "Análise bivariada\n\nNa Tabela @ref(tab:corr1) é apresentado seis observações das variáveis \\(X\\) e \\(Y\\).\n\n\n\n\n\n\nSeis observações das variáveis X e Y.\n\n\n\n\nX\n\n\n7\n\n\n11\n\n\n7\n\n\n16\n\n\n11\n\n\n7\n\n\n\n\nY\n\n\n7\n\n\n12\n\n\n8\n\n\n16\n\n\n13\n\n\n7\n\n\n\n\n\nTRUE\n\n\n\nx <- c(7,11,7,16,11,7)\ny <- c(7,12,8,16,13,7)\ndados3 <- data.frame(X=x, Y=y)\ndados3\n\n   X  Y\n1  7  7\n2 11 12\n3  7  8\n4 16 16\n5 11 13\n6  7  7\n\n\n\nFaça um diagrama de dispersão (\\(X\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(Y~X, dados3) \n\n\n\n\nDiagrama de dispersão.\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(x,y)\n\n[1] 13.1\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(x,y)\n\n[1] 0.9757751\n\n# ou \ncov(x,y)/(sd(x)*sd(y))\n\n[1] 0.9757751\n\n\n\nO diretor de uma escola quer saber se há associação entre a média escolar (\\(ME\\)) e o desempenho em um simulado (\\(SIM\\)). Na Tabela @ref(tab:corr2) é apresentado uma amostra de seis alunos.\n\n\n\n\n\n\nSeis observações das variáveis ME e SIM.\n\n\n\n\nAluno\n\n\n1.0\n\n\n2.0\n\n\n3.0\n\n\n4.0\n\n\n5.0\n\n\n6.0\n\n\n\n\nME\n\n\n5.3\n\n\n6.2\n\n\n5.1\n\n\n7.8\n\n\n6.4\n\n\n5.1\n\n\n\n\nSIM\n\n\n5.5\n\n\n6.6\n\n\n5.4\n\n\n7.6\n\n\n7.2\n\n\n5.3\n\n\n\n\n\nTRUE\n\n\n\nME     <- c(5.3,6.2,5.1,7.8,6.4,5.1)\nSIM    <- c(5.5,6.6,5.4,7.6,7.2,5.3)\ndados4 <- data.frame(Aluno=1:6,ME, SIM)\ndados4\n\n  Aluno  ME SIM\n1     1 5.3 5.5\n2     2 6.2 6.6\n3     3 5.1 5.4\n4     4 7.8 7.6\n5     5 6.4 7.2\n6     6 5.1 5.3\n\n\n\nFaça um diagrama de dispersão (\\(ME\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(ME~SIM,data = dados4) \n\n\n\n\nDiagrama de dispersão\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(dados4$ME,dados4$SIM)\n\n[1] 1.005333\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(dados4$ME,dados4$SIM)\n\n[1] 0.9511981\n\n# ou \ncov(dados4$ME,dados4$SIM)/(sd(dados4$ME)*sd(dados4$SIM))\n\n[1] 0.9511981\n\n\n\nTempo de caminhada \\(\\times\\) Gordura corporal. Dados de tempo semanal de caminhada (horas) e a gordura corporal (%) de oito indivíduos do sexo masculino com idade acima de 60 anos são apresentados na Tabela @ref(tab:corr3).\n\n\n\n\n\n\nTempo de caminhada (horas) e gordura corporal (%) de oito indivíduos.\n\n\n\n\nIndivíduo\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n\n\nTempo\n\n\n6\n\n\n12\n\n\n4\n\n\n2\n\n\n5\n\n\n7\n\n\n14\n\n\n10\n\n\n\n\nGordura\n\n\n22\n\n\n11\n\n\n23\n\n\n25\n\n\n21\n\n\n19\n\n\n9\n\n\n12\n\n\n\n\n\nTRUE\n\n\n\nFaça um diagrama de dispersão (coloque o tempo no eixo horizontal).\nCalcule a covariância da amostra.\nCalcule e interprete a correlação da amostra."
  },
  {
    "objectID": "about.html#análise-bivariada",
    "href": "about.html#análise-bivariada",
    "title": "Lista de exercícios",
    "section": "Análise bivariada",
    "text": "Análise bivariada\n\nNa Tabela @ref(tab:corr1) é apresentado seis observações das variáveis \\(X\\) e \\(Y\\).\n\n\n\n\n\n\nSeis observações das variáveis X e Y.\n\n\n\n\nX\n\n\n7\n\n\n11\n\n\n7\n\n\n16\n\n\n11\n\n\n7\n\n\n\n\nY\n\n\n7\n\n\n12\n\n\n8\n\n\n16\n\n\n13\n\n\n7\n\n\n\n\n\nTRUE\n\n\n\nx <- c(7,11,7,16,11,7)\ny <- c(7,12,8,16,13,7)\ndados3 <- data.frame(X=x, Y=y)\ndados3\n\n   X  Y\n1  7  7\n2 11 12\n3  7  8\n4 16 16\n5 11 13\n6  7  7\n\n\n\nFaça um diagrama de dispersão (\\(X\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(Y~X, dados3) \n\n\n\n\nDiagrama de dispersão.\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(x,y)\n\n[1] 13.1\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(x,y)\n\n[1] 0.9757751\n\n# ou \ncov(x,y)/(sd(x)*sd(y))\n\n[1] 0.9757751\n\n\n\nO diretor de uma escola quer saber se há associação entre a média escolar (\\(ME\\)) e o desempenho em um simulado (\\(SIM\\)). Na Tabela @ref(tab:corr2) é apresentado uma amostra de seis alunos.\n\n\n\n\n\n\nSeis observações das variáveis ME e SIM.\n\n\n\n\nAluno\n\n\n1.0\n\n\n2.0\n\n\n3.0\n\n\n4.0\n\n\n5.0\n\n\n6.0\n\n\n\n\nME\n\n\n5.3\n\n\n6.2\n\n\n5.1\n\n\n7.8\n\n\n6.4\n\n\n5.1\n\n\n\n\nSIM\n\n\n5.5\n\n\n6.6\n\n\n5.4\n\n\n7.6\n\n\n7.2\n\n\n5.3\n\n\n\n\n\nTRUE\n\n\n\nME     <- c(5.3,6.2,5.1,7.8,6.4,5.1)\nSIM    <- c(5.5,6.6,5.4,7.6,7.2,5.3)\ndados4 <- data.frame(Aluno=1:6,ME, SIM)\ndados4\n\n  Aluno  ME SIM\n1     1 5.3 5.5\n2     2 6.2 6.6\n3     3 5.1 5.4\n4     4 7.8 7.6\n5     5 6.4 7.2\n6     6 5.1 5.3\n\n\n\nFaça um diagrama de dispersão (\\(ME\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(ME~SIM,data = dados4) \n\n\n\n\nDiagrama de dispersão\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(dados4$ME,dados4$SIM)\n\n[1] 1.005333\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(dados4$ME,dados4$SIM)\n\n[1] 0.9511981\n\n# ou \ncov(dados4$ME,dados4$SIM)/(sd(dados4$ME)*sd(dados4$SIM))\n\n[1] 0.9511981\n\n\n\nTempo de caminhada \\(\\times\\) Gordura corporal. Dados de tempo semanal de caminhada (horas) e a gordura corporal (%) de oito indivíduos do sexo masculino com idade acima de 60 anos são apresentados na Tabela @ref(tab:corr3).\n\n\n\n\n\n\nTempo de caminhada (horas) e gordura corporal (%) de oito indivíduos.\n\n\n\n\nIndivíduo\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n\n\nTempo\n\n\n6\n\n\n12\n\n\n4\n\n\n2\n\n\n5\n\n\n7\n\n\n14\n\n\n10\n\n\n\n\nGordura\n\n\n22\n\n\n11\n\n\n23\n\n\n25\n\n\n21\n\n\n19\n\n\n9\n\n\n12\n\n\n\n\n\nTRUE\n\n\n\nFaça um diagrama de dispersão (coloque o tempo no eixo horizontal).\nCalcule a covariância da amostra.\nCalcule e interprete a correlação da amostra."
  },
  {
    "objectID": "lista.html#análise-bivariada",
    "href": "lista.html#análise-bivariada",
    "title": "Lista de exercícios",
    "section": "Análise bivariada",
    "text": "Análise bivariada\n\nNa Table 4 é apresentado seis observações das variáveis \\(X\\) e \\(Y\\).\n\n\n\n\n\nTable 4:  Seis observações das variáveis X e Y. \n\n  \n    X \n    7 \n    11 \n    7 \n    16 \n    11 \n    7 \n  \n  \n    Y \n    7 \n    12 \n    8 \n    16 \n    13 \n    7 \n  \n\n\n\n\n\n\n\nx <- c(7,11,7,16,11,7)\ny <- c(7,12,8,16,13,7)\ndados3 <- data.frame(X=x, Y=y)\ndados3\n\n   X  Y\n1  7  7\n2 11 12\n3  7  8\n4 16 16\n5 11 13\n6  7  7\n\n\n\nFaça um diagrama de dispersão (\\(X\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(Y~X, dados3) \n\n\n\n\nDiagrama de dispersão.\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(x,y)\n\n[1] 13.1\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(x,y)\n\n[1] 0.9757751\n\n# ou \ncov(x,y)/(sd(x)*sd(y))\n\n[1] 0.9757751\n\n\n\nO diretor de uma escola quer saber se há associação entre a média escolar (\\(ME\\)) e o desempenho em um simulado (\\(SIM\\)). Na Table 5 é apresentado uma amostra de seis alunos.\n\n\n\n\n\nTable 5:  Seis observações das variáveis ME e SIM. \n\n  \n    Aluno \n    1.0 \n    2.0 \n    3.0 \n    4.0 \n    5.0 \n    6.0 \n  \n  \n    ME \n    5.3 \n    6.2 \n    5.1 \n    7.8 \n    6.4 \n    5.1 \n  \n  \n    SIM \n    5.5 \n    6.6 \n    5.4 \n    7.6 \n    7.2 \n    5.3 \n  \n\n\n\n\n\n\n\nME     <- c(5.3,6.2,5.1,7.8,6.4,5.1)\nSIM    <- c(5.5,6.6,5.4,7.6,7.2,5.3)\ndados4 <- data.frame(Aluno=1:6,ME, SIM)\ndados4\n\n  Aluno  ME SIM\n1     1 5.3 5.5\n2     2 6.2 6.6\n3     3 5.1 5.4\n4     4 7.8 7.6\n5     5 6.4 7.2\n6     6 5.1 5.3\n\n\n\nFaça um diagrama de dispersão (\\(ME\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(SIM~ME,data = dados4) \n\n\n\n\nDiagrama de dispersão\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(dados4$ME,dados4$SIM)\n\n[1] 1.005333\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(dados4$ME,dados4$SIM)\n\n[1] 0.9511981\n\n# ou \ncov(dados4$ME,dados4$SIM)/(sd(dados4$ME)*sd(dados4$SIM))\n\n[1] 0.9511981\n\n\n\nTempo de caminhada \\(\\times\\) Gordura corporal. Dados de tempo semanal de caminhada (horas) e a gordura corporal (%) de oito indivíduos do sexo masculino com idade acima de 60 anos são apresentados na Table 6.\n\n\n\n\n\nTable 6:  Tempo de caminhada (horas) e gordura corporal (%) de oito indivíduos. \n\n  \n    Indivíduo \n    1 \n    2 \n    3 \n    4 \n    5 \n    6 \n    7 \n    8 \n  \n  \n    Tempo \n    6 \n    12 \n    4 \n    2 \n    5 \n    7 \n    14 \n    10 \n  \n  \n    Gordura \n    22 \n    11 \n    23 \n    25 \n    21 \n    19 \n    9 \n    12 \n  \n\n\n\n\n\n\n\nTempo   <- c(6,12,4,2,5,7,14,10)\nGordura <- c(22,11,23,25,21,19,9,12)\ndados5  <- data.frame(Ind=1:8,Tempo, Gordura)\ndados5\n\n  Ind Tempo Gordura\n1   1     6      22\n2   2    12      11\n3   3     4      23\n4   4     2      25\n5   5     5      21\n6   6     7      19\n7   7    14       9\n8   8    10      12\n\n\n\nFaça um diagrama de dispersão (coloque o tempo no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(Gordura~Tempo,data = dados5) \n\n\n\n\nDiagrama de dispersão\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(dados5$Tempo,dados5$Gordura)\n\n[1] -25\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(dados5$Tempo,dados5$Gordura)\n\n[1] -0.9804268"
  },
  {
    "objectID": "benford.html#análise-bivariada",
    "href": "benford.html#análise-bivariada",
    "title": "Lista de exercícios",
    "section": "Análise bivariada",
    "text": "Análise bivariada\n\nNa Tabela @ref(tab:corr1) é apresentado seis observações das variáveis \\(X\\) e \\(Y\\).\n\n\n\n\n\n\nSeis observações das variáveis X e Y.\n\n\n\n\nX\n\n\n7\n\n\n11\n\n\n7\n\n\n16\n\n\n11\n\n\n7\n\n\n\n\nY\n\n\n7\n\n\n12\n\n\n8\n\n\n16\n\n\n13\n\n\n7\n\n\n\n\n\nTRUE\n\n\n\nx <- c(7,11,7,16,11,7)\ny <- c(7,12,8,16,13,7)\ndados3 <- data.frame(X=x, Y=y)\ndados3\n\n   X  Y\n1  7  7\n2 11 12\n3  7  8\n4 16 16\n5 11 13\n6  7  7\n\n\n\nFaça um diagrama de dispersão (\\(X\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(Y~X, dados3) \n\n\n\n\nDiagrama de dispersão.\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(x,y)\n\n[1] 13.1\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(x,y)\n\n[1] 0.9757751\n\n# ou \ncov(x,y)/(sd(x)*sd(y))\n\n[1] 0.9757751\n\n\n\nO diretor de uma escola quer saber se há associação entre a média escolar (\\(ME\\)) e o desempenho em um simulado (\\(SIM\\)). Na Tabela @ref(tab:corr2) é apresentado uma amostra de seis alunos.\n\n\n\n\n\n\nSeis observações das variáveis ME e SIM.\n\n\n\n\nAluno\n\n\n1.0\n\n\n2.0\n\n\n3.0\n\n\n4.0\n\n\n5.0\n\n\n6.0\n\n\n\n\nME\n\n\n5.3\n\n\n6.2\n\n\n5.1\n\n\n7.8\n\n\n6.4\n\n\n5.1\n\n\n\n\nSIM\n\n\n5.5\n\n\n6.6\n\n\n5.4\n\n\n7.6\n\n\n7.2\n\n\n5.3\n\n\n\n\n\nTRUE\n\n\n\nME     <- c(5.3,6.2,5.1,7.8,6.4,5.1)\nSIM    <- c(5.5,6.6,5.4,7.6,7.2,5.3)\ndados4 <- data.frame(Aluno=1:6,ME, SIM)\ndados4\n\n  Aluno  ME SIM\n1     1 5.3 5.5\n2     2 6.2 6.6\n3     3 5.1 5.4\n4     4 7.8 7.6\n5     5 6.4 7.2\n6     6 5.1 5.3\n\n\n\nFaça um diagrama de dispersão (\\(ME\\) no eixo horizontal).\n\n\npar(bg=\"white\")\nplot(ME~SIM,data = dados4) \n\n\n\n\nDiagrama de dispersão\n\n\n\n\n\nCalcule a covariância da amostra.\n\n\ncov(dados4$ME,dados4$SIM)\n\n[1] 1.005333\n\n\n\nCalcule e interprete a correlação da amostra.\n\n\ncor(dados4$ME,dados4$SIM)\n\n[1] 0.9511981\n\n# ou \ncov(dados4$ME,dados4$SIM)/(sd(dados4$ME)*sd(dados4$SIM))\n\n[1] 0.9511981\n\n\n\nTempo de caminhada \\(\\times\\) Gordura corporal. Dados de tempo semanal de caminhada (horas) e a gordura corporal (%) de oito indivíduos do sexo masculino com idade acima de 60 anos são apresentados na Tabela @ref(tab:corr3).\n\n\n\n\n\n\nTempo de caminhada (horas) e gordura corporal (%) de oito indivíduos.\n\n\n\n\nIndivíduo\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n\n\nTempo\n\n\n6\n\n\n12\n\n\n4\n\n\n2\n\n\n5\n\n\n7\n\n\n14\n\n\n10\n\n\n\n\nGordura\n\n\n22\n\n\n11\n\n\n23\n\n\n25\n\n\n21\n\n\n19\n\n\n9\n\n\n12\n\n\n\n\n\nTRUE\n\n\n\nFaça um diagrama de dispersão (coloque o tempo no eixo horizontal).\nCalcule a covariância da amostra.\nCalcule e interprete a correlação da amostra."
  },
  {
    "objectID": "benford.html#juros-compostos",
    "href": "benford.html#juros-compostos",
    "title": "Benford",
    "section": "Juros compostos",
    "text": "Juros compostos\nComo um exemplo, vamos trabalhar a ideia de juros compostos, em que o juro incide sobre o capital inicial e sobre os juros acumulados. A expressão para o cálculo de juros compostos tem a mesma estrutura da Equação @ref(eq:cresc), ou seja,\n\\[ M = C (1 + i)^t \\] em que \\(M\\) é o montante no instante \\(t\\), \\(C\\) é o capital inicial quando \\(t=0\\), e \\(i\\) é a taxa de juros fixa. Observe os dados abaixo. Eles foram obtidos usando um capital inicial de R$100,00 com uma taxa de crescimento de 2.5% por período. Observa que, inicialmente, o primeiro dígito significativo igual a 1 aparece nos 28 primeiros valores. Depois, o crescimento é mais rápido e o sistema apresenta 16 valores com o primeiro dígito significativo igual a 2. O crescimento se acentua e o dígito 3 aparece nos próximos 12 valores. Como o capital cresce cada vez mais rápido, os próximos dígitos aparecem cada vez menos. Veja o dígito 9, ele aparece apenas 5 vezes. Logo após, o dígito 1 aparece novamente por mais 28 períodos.\n\n# Juros compostos\nc <- 100\ni <- 0.025\nt <- 1:190\nm <- c*(1+i)^t\nm\n\n  [1]   102.5000   105.0625   107.6891   110.3813   113.1408   115.9693\n  [7]   118.8686   121.8403   124.8863   128.0085   131.2087   134.4889\n [13]   137.8511   141.2974   144.8298   148.4506   152.1618   155.9659\n [19]   159.8650   163.8616   167.9582   172.1571   176.4611   180.8726\n [25]   185.3944   190.0293   194.7800   199.6495   204.6407   209.7568\n [31]   215.0007   220.3757   225.8851   231.5322   237.3205   243.2535\n [37]   249.3349   255.5682   261.9574   268.5064   275.2190   282.0995\n [43]   289.1520   296.3808   303.7903   311.3851   319.1697   327.1490\n [49]   335.3277   343.7109   352.3036   361.1112   370.1390   379.3925\n [55]   388.8773   398.5992   408.5642   418.7783   429.2478   439.9790\n [61]   450.9784   462.2529   473.8092   485.6545   497.7958   510.2407\n [67]   522.9967   536.0717   549.4734   563.2103   577.2905   591.7228\n [73]   606.5159   621.6788   637.2207   653.1513   669.4800   686.2170\n [79]   703.3725   720.9568   738.9807   757.4552   776.3916   795.8014\n [85]   815.6964   836.0888   856.9911   878.4158   900.3762   922.8856\n [91]   945.9578   969.6067   993.8469  1018.6931  1044.1604  1070.2644\n [97]  1097.0210  1124.4465  1152.5577  1181.3716  1210.9059  1241.1786\n[103]  1272.2080  1304.0132  1336.6136  1370.0289  1404.2796  1439.3866\n[109]  1475.3713  1512.2556  1550.0620  1588.8135  1628.5338  1669.2472\n[115]  1710.9784  1753.7528  1797.5967  1842.5366  1888.6000  1935.8150\n[121]  1984.2104  2033.8156  2084.6610  2136.7775  2190.1970  2244.9519\n[127]  2301.0757  2358.6026  2417.5676  2478.0068  2539.9570  2603.4559\n[133]  2668.5423  2735.2559  2803.6373  2873.7282  2945.5714  3019.2107\n[139]  3094.6910  3172.0583  3251.3597  3332.6437  3415.9598  3501.3588\n[145]  3588.8928  3678.6151  3770.5805  3864.8450  3961.4661  4060.5027\n[151]  4162.0153  4266.0657  4372.7173  4482.0353  4594.0862  4708.9383\n[157]  4826.6618  4947.3283  5071.0115  5197.7868  5327.7315  5460.9248\n[163]  5597.4479  5737.3841  5880.8187  6027.8392  6178.5351  6332.9985\n[169]  6491.3235  6653.6066  6819.9467  6990.4454  7165.2065  7344.3367\n[175]  7527.9451  7716.1437  7909.0473  8106.7735  8309.4428  8517.1789\n[181]  8730.1084  8948.3611  9172.0701  9401.3719  9636.4062  9877.3163\n[187] 10124.2492 10377.3555 10636.7894 10902.7091\n\n\nVamos agora extrair os primeiros dígitos significativos do nosso conjunto de dados.\n\ndddd <- as.data.frame(m)\naux1 <- c()\nfor (i in 1:dim(dddd)[1]) {\n  n <- as.integer(dddd[i,1])\n  aux2 <- c()\n  while (n > 0) {\n    r = n %% 10\n    aux2 <- c(aux2,r)\n    n = n %/% 10\n  }\n  ll <- aux2[length(aux2)]\n  aux1 <- c(aux1,ll)\n}\n\nObservamos a distribuição de frequências destes valores abaixo.\n\n#\ntt <- table(aux1)\nround(tt/sum(tt),4)\n\naux1\n     1      2      3      4      5      6      7      8      9 \n0.3158 0.1684 0.1263 0.0947 0.0737 0.0684 0.0579 0.0474 0.0474 \n\n\nPodemos comparar os dados teóricos apresentados na Tabela @ref(tab:ben1) e na Figura @ref(fig:freqben1) com os dos juros compostos. Isto pode ser visto na Tabela @ref(tab:ben2).\n\n\n\n\n\nComparação das frequências teórica da lei de Benford e dos dados de juros compostos.\n\n\n\n\nValores\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n\n\n\n\nTeórico\n\n\n0.301\n\n\n0.1761\n\n\n0.1249\n\n\n0.0969\n\n\n0.0792\n\n\n0.0669\n\n\n0.058\n\n\n0.0512\n\n\n0.0458\n\n\n\n\nExemplo\n\n\n0.3158\n\n\n0.1684\n\n\n0.1263\n\n\n0.0947\n\n\n0.0737\n\n\n0.0684\n\n\n0.0579\n\n\n0.0474\n\n\n0.0474\n\n\n\n\n\nTRUE"
  },
  {
    "objectID": "benford.html#multiplicação-de-valores-fraudes-contábeis",
    "href": "benford.html#multiplicação-de-valores-fraudes-contábeis",
    "title": "Benford",
    "section": "Multiplicação de valores (fraudes contábeis)",
    "text": "Multiplicação de valores (fraudes contábeis)\nDados contábeis e econômicos geralmente são o resultado da multiplicação de vários números. Quando temos esse caso, os dados se aproximam da distribuição de Benford. Por isto essa distribuição é usada para identificar fraudes. Se alguém alterar os dados contábeis de um conjunto de dados por meio de fraudes, esse erro poderá se apresentar quando compararmos a frequência dos primeiros dígitos com a distribuição de Benford.\nPor exemplo, vamos gerar dados a partir de três distribuições de probabilidades, uma normal (N(200,25)), outra qui-quadrado (\\(\\chi^2(5)\\)) e uma uniforme (U(0,1)). Geramos 10 mil valores aleatórios a partir de cada distribuição e alocamos em três coluna, conforme foram gerados.\n\nset.seed(1)\ndn <- rnorm(10000,200,5)\ndp <- rchisq(10000,5)\ndu <- runif(10000,0,1)\nda <- data.frame(dn,dp,du)\nhead(da)\n\n        dn       dp         du\n1 196.8677 2.048481 0.55955577\n2 200.9182 2.720009 0.16710544\n3 195.8219 1.349506 0.07304196\n4 207.9764 2.688898 0.64984458\n5 201.6475 3.190323 0.36573156\n6 195.8977 2.449519 0.23948351\n\n\nDepois fizemos o produto dos valores dispostos em cada linha do conjunto de dados.\n\nda2 <- data.frame(da,\"dn.dp.du\" = dn*dp*du)\nhead(da2)\n\n        dn       dp         du  dn.dp.du\n1 196.8677 2.048481 0.55955577 225.65758\n2 200.9182 2.720009 0.16710544  91.32301\n3 195.8219 1.349506 0.07304196  19.30227\n4 207.9764 2.688898 0.64984458 363.41084\n5 201.6475 3.190323 0.36573156 235.28273\n6 195.8977 2.449519 0.23948351 114.91737\n\n\nAgora vamos obter o primeiro dígito da última coluna dos dados apresentados acima e, então, comparar a frequência deles com a distribuição teórica de Benford.\n\ndt <- dn*dp*du\ndddd <- as.data.frame(dt)\naux1 <- c()\nfor (i in 1:dim(dddd)[1]) {\n  n <- as.integer(dddd[i,1])\n  aux2 <- c()\n  while (n > 0) {\n    r = n %% 10\n    aux2 <- c(aux2,r)\n    n = n %/% 10\n  }\n  ll <- aux2[length(aux2)]\n  aux1 <- c(aux1,ll)\n}\nddt <- aux1\n#\nttt  <- table(ddt)\nreat <- round(ttt/sum(ttt),4)\n#\nx2  <- seq(1,9,0.1)\nteo2 <- round(log10(1+1/x2),4)\n\nNa Figura @ref(fig:freqben4), observamos os dados gerados aleatoriamente (sem fraude), ou seja, a frequência dos primeiros dígitos da coluna que representa o produto da multiplicação dos valores gerados pelas distribuições propostas anteriormente. Estes valores são representados pelos pontos, enquanto que, a distribuição teórica é representada pela curva. É possível notar uma grande concordância entre os pontos e a curva.\n\n\n\n\n\nAs frequências da lei de Benford e dados gerados aleatóriamente (sem fraude)."
  },
  {
    "objectID": "normal.html#juros-compostos",
    "href": "normal.html#juros-compostos",
    "title": "Benford",
    "section": "Juros compostos",
    "text": "Juros compostos\nComo um exemplo, vamos trabalhar a ideia de juros compostos, em que o juro incide sobre o capital inicial e sobre os juros acumulados. A expressão para o cálculo de juros compostos tem a mesma estrutura da Equação @ref(eq:cresc), ou seja,\n\\[ M = C (1 + i)^t \\] em que \\(M\\) é o montante no instante \\(t\\), \\(C\\) é o capital inicial quando \\(t=0\\), e \\(i\\) é a taxa de juros fixa. Observe os dados abaixo. Eles foram obtidos usando um capital inicial de R$100,00 com uma taxa de crescimento de 2.5% por período. Observa que, inicialmente, o primeiro dígito significativo igual a 1 aparece nos 28 primeiros valores. Depois, o crescimento é mais rápido e o sistema apresenta 16 valores com o primeiro dígito significativo igual a 2. O crescimento se acentua e o dígito 3 aparece nos próximos 12 valores. Como o capital cresce cada vez mais rápido, os próximos dígitos aparecem cada vez menos. Veja o dígito 9, ele aparece apenas 5 vezes. Logo após, o dígito 1 aparece novamente por mais 28 períodos.\n\n# Juros compostos\nc <- 100\ni <- 0.025\nt <- 1:190\nm <- c*(1+i)^t\nm\n\n  [1]   102.5000   105.0625   107.6891   110.3813   113.1408   115.9693\n  [7]   118.8686   121.8403   124.8863   128.0085   131.2087   134.4889\n [13]   137.8511   141.2974   144.8298   148.4506   152.1618   155.9659\n [19]   159.8650   163.8616   167.9582   172.1571   176.4611   180.8726\n [25]   185.3944   190.0293   194.7800   199.6495   204.6407   209.7568\n [31]   215.0007   220.3757   225.8851   231.5322   237.3205   243.2535\n [37]   249.3349   255.5682   261.9574   268.5064   275.2190   282.0995\n [43]   289.1520   296.3808   303.7903   311.3851   319.1697   327.1490\n [49]   335.3277   343.7109   352.3036   361.1112   370.1390   379.3925\n [55]   388.8773   398.5992   408.5642   418.7783   429.2478   439.9790\n [61]   450.9784   462.2529   473.8092   485.6545   497.7958   510.2407\n [67]   522.9967   536.0717   549.4734   563.2103   577.2905   591.7228\n [73]   606.5159   621.6788   637.2207   653.1513   669.4800   686.2170\n [79]   703.3725   720.9568   738.9807   757.4552   776.3916   795.8014\n [85]   815.6964   836.0888   856.9911   878.4158   900.3762   922.8856\n [91]   945.9578   969.6067   993.8469  1018.6931  1044.1604  1070.2644\n [97]  1097.0210  1124.4465  1152.5577  1181.3716  1210.9059  1241.1786\n[103]  1272.2080  1304.0132  1336.6136  1370.0289  1404.2796  1439.3866\n[109]  1475.3713  1512.2556  1550.0620  1588.8135  1628.5338  1669.2472\n[115]  1710.9784  1753.7528  1797.5967  1842.5366  1888.6000  1935.8150\n[121]  1984.2104  2033.8156  2084.6610  2136.7775  2190.1970  2244.9519\n[127]  2301.0757  2358.6026  2417.5676  2478.0068  2539.9570  2603.4559\n[133]  2668.5423  2735.2559  2803.6373  2873.7282  2945.5714  3019.2107\n[139]  3094.6910  3172.0583  3251.3597  3332.6437  3415.9598  3501.3588\n[145]  3588.8928  3678.6151  3770.5805  3864.8450  3961.4661  4060.5027\n[151]  4162.0153  4266.0657  4372.7173  4482.0353  4594.0862  4708.9383\n[157]  4826.6618  4947.3283  5071.0115  5197.7868  5327.7315  5460.9248\n[163]  5597.4479  5737.3841  5880.8187  6027.8392  6178.5351  6332.9985\n[169]  6491.3235  6653.6066  6819.9467  6990.4454  7165.2065  7344.3367\n[175]  7527.9451  7716.1437  7909.0473  8106.7735  8309.4428  8517.1789\n[181]  8730.1084  8948.3611  9172.0701  9401.3719  9636.4062  9877.3163\n[187] 10124.2492 10377.3555 10636.7894 10902.7091\n\n\nVamos agora extrair os primeiros dígitos significativos do nosso conjunto de dados.\n\ndddd <- as.data.frame(m)\naux1 <- c()\nfor (i in 1:dim(dddd)[1]) {\n  n <- as.integer(dddd[i,1])\n  aux2 <- c()\n  while (n > 0) {\n    r = n %% 10\n    aux2 <- c(aux2,r)\n    n = n %/% 10\n  }\n  ll <- aux2[length(aux2)]\n  aux1 <- c(aux1,ll)\n}\n\nObservamos a distribuição de frequências destes valores abaixo.\n\n#\ntt <- table(aux1)\nround(tt/sum(tt),4)\n\naux1\n     1      2      3      4      5      6      7      8      9 \n0.3158 0.1684 0.1263 0.0947 0.0737 0.0684 0.0579 0.0474 0.0474 \n\n\nPodemos comparar os dados teóricos apresentados na Tabela @ref(tab:ben1) e na Figura @ref(fig:freqben1) com os dos juros compostos. Isto pode ser visto na Tabela @ref(tab:ben2).\n\n\n\n\n\nComparação das frequências teórica da lei de Benford e dos dados de juros compostos.\n\n\n\n\nValores\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n\n\n\n\nTeórico\n\n\n0.301\n\n\n0.1761\n\n\n0.1249\n\n\n0.0969\n\n\n0.0792\n\n\n0.0669\n\n\n0.058\n\n\n0.0512\n\n\n0.0458\n\n\n\n\nExemplo\n\n\n0.3158\n\n\n0.1684\n\n\n0.1263\n\n\n0.0947\n\n\n0.0737\n\n\n0.0684\n\n\n0.0579\n\n\n0.0474\n\n\n0.0474\n\n\n\n\n\nTRUE"
  },
  {
    "objectID": "normal.html#multiplicação-de-valores-fraudes-contábeis",
    "href": "normal.html#multiplicação-de-valores-fraudes-contábeis",
    "title": "Benford",
    "section": "Multiplicação de valores (fraudes contábeis)",
    "text": "Multiplicação de valores (fraudes contábeis)\nDados contábeis e econômicos geralmente são o resultado da multiplicação de vários números. Quando temos esse caso, os dados se aproximam da distribuição de Benford. Por isto essa distribuição é usada para identificar fraudes. Se alguém alterar os dados contábeis de um conjunto de dados por meio de fraudes, esse erro poderá se apresentar quando compararmos a frequência dos primeiros dígitos com a distribuição de Benford.\nPor exemplo, vamos gerar dados a partir de três distribuições de probabilidades, uma normal (N(200,25)), outra qui-quadrado (\\(\\chi^2(5)\\)) e uma uniforme (U(0,1)). Geramos 10 mil valores aleatórios a partir de cada distribuição e alocamos em três coluna, conforme foram gerados.\n\nset.seed(1)\ndn <- rnorm(10000,200,5)\ndp <- rchisq(10000,5)\ndu <- runif(10000,0,1)\nda <- data.frame(dn,dp,du)\nhead(da)\n\n        dn       dp         du\n1 196.8677 2.048481 0.55955577\n2 200.9182 2.720009 0.16710544\n3 195.8219 1.349506 0.07304196\n4 207.9764 2.688898 0.64984458\n5 201.6475 3.190323 0.36573156\n6 195.8977 2.449519 0.23948351\n\n\nDepois fizemos o produto dos valores dispostos em cada linha do conjunto de dados.\n\nda2 <- data.frame(da,\"dn.dp.du\" = dn*dp*du)\nhead(da2)\n\n        dn       dp         du  dn.dp.du\n1 196.8677 2.048481 0.55955577 225.65758\n2 200.9182 2.720009 0.16710544  91.32301\n3 195.8219 1.349506 0.07304196  19.30227\n4 207.9764 2.688898 0.64984458 363.41084\n5 201.6475 3.190323 0.36573156 235.28273\n6 195.8977 2.449519 0.23948351 114.91737\n\n\nAgora vamos obter o primeiro dígito da última coluna dos dados apresentados acima e, então, comparar a frequência deles com a distribuição teórica de Benford.\n\ndt <- dn*dp*du\ndddd <- as.data.frame(dt)\naux1 <- c()\nfor (i in 1:dim(dddd)[1]) {\n  n <- as.integer(dddd[i,1])\n  aux2 <- c()\n  while (n > 0) {\n    r = n %% 10\n    aux2 <- c(aux2,r)\n    n = n %/% 10\n  }\n  ll <- aux2[length(aux2)]\n  aux1 <- c(aux1,ll)\n}\nddt <- aux1\n#\nttt  <- table(ddt)\nreat <- round(ttt/sum(ttt),4)\n#\nx2  <- seq(1,9,0.1)\nteo2 <- round(log10(1+1/x2),4)\n\nNa Figura @ref(fig:freqben4), observamos os dados gerados aleatoriamente (sem fraude), ou seja, a frequência dos primeiros dígitos da coluna que representa o produto da multiplicação dos valores gerados pelas distribuições propostas anteriormente. Estes valores são representados pelos pontos, enquanto que, a distribuição teórica é representada pela curva. É possível notar uma grande concordância entre os pontos e a curva.\n\n\n\n\n\nAs frequências da lei de Benford e dados gerados aleatóriamente (sem fraude)."
  },
  {
    "objectID": "normal.html",
    "href": "normal.html",
    "title": "Normal",
    "section": "",
    "text": "Introdução1\nA distribuição normal é uma das mais importantes distribuições contínuas de probabilidade e pode ser escrita como\n\n\n\n\n\nFootnotes\n\n\nCaso encontre erros, queira fazer comentários, ou trocar uma ideia sobre o artigo, por favor, me escreva: omarcnpereiraead@gmail.com↩︎"
  },
  {
    "objectID": "DistrNormal.html",
    "href": "DistrNormal.html",
    "title": "Distribuição Normal",
    "section": "",
    "text": "Introdução1\nA distribuição normal é uma das mais importantes distribuições contínuas de probabilidade e pode ser escrita como\n\\[\nf(x)= \\frac{1}{\\sqrt{2 \\pi \\sigma}} e^{- \\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}}\n,\n\\tag{1}\\]\nem que \\(\\mu\\) e \\(\\sigma\\) são a média e a variância da distribuição. O objetivo deste artigo é apresentar uma demonstração dessa distribuição em forma de sino a partir da exponenciação de um polinômio de segundo grau, isto é,\n\\[\nf(x)= exp \\{ ax^{2} + bx + c \\}\n,\n\\tag{2}\\]\nem que \\(a\\), \\(b\\) e \\(c\\) são constantes. Por exemplo, podemos representar graficamente a exponenciação desse polinômio para \\(a=-2\\), \\(b=0\\) e \\(c=1\\), ou seja,\n\n\n\n\n\nFigure 1: Representação de uma curva em forma de sino (a área sob a curva não é um).\n\n\n\n\nO gráfico apresentado na Figura Figure 1 não tem área sob a curva igual a um, mas tem o formado de sino equivalente à curva normal.\nPara que esta função tenha um máximo, faremos \\(a<0\\). Assim \\(a=- \\alpha\\) com \\(\\alpha > 0\\). As constantes \\(b\\), a qual move o pico central da distribuição ao longo de \\(x\\), e \\(c\\) são escolhidas a fim de que\n\\[\n\\int_{- \\infty}^{+ \\infty} f(x) \\hspace{0.2cm} dx = 1\n.\n\\tag{3}\\]\n\n\nDesenvolvimento\nComeçaremos agora um trabalho algébrico. Assim\n\\[\nf(x)= exp \\{ -(\\alpha x^{2} - bx) \\} exp \\{ {c} \\}\n,\n\\tag{4}\\]\nem que, completando quadrados na primeira exponencial da Equação (Equation 4), temos\n\\[\\begin{equation*}\n\\alpha x^{2} - bx = \\left( \\sqrt{ \\alpha } x - \\frac{b}{2 \\sqrt{ \\alpha }} \\right)^{2} - \\left(\\frac{b}{2 \\sqrt{ \\alpha}}\\right)^{2}\n.\n\\end{equation*}\\]\nDessa forma\n\\[\\begin{equation*}\nf(x)= exp \\left\\{ -\\left( \\sqrt{\\alpha} x - \\frac{b}{2 \\sqrt{ \\alpha }} \\right)^{2}  \\right\\}  exp \\left\\{ c - \\left( \\frac{b}{2 \\sqrt{ \\alpha}} \\right)^{2}  \\right\\}\n,\n\\end{equation*}\\]\ne, como \\(exp \\left\\{ c - \\left( \\frac{b}{2 \\sqrt{ \\alpha}} \\right)^{2} \\right\\}\\) é uma constante, faremos\n\\[\\begin{equation*}\n\\beta = exp \\left\\{ c - \\left( \\frac{b}{2 \\sqrt{ \\alpha}} \\right)^{2}  \\right\\}\n,\n\\end{equation*}\\]\nficando com\n\\[\\begin{equation*}\nf(x) \\hspace{0.2cm} = \\hspace{0.2cm} \\beta \\hspace{0.2cm} exp \\left\\{ -\\left( \\sqrt{\\alpha} x - \\frac{b}{2 \\sqrt{ \\alpha }} \\right)^{2}  \\right\\}\n.\n\\end{equation*}\\]\nAgora fazendo \\(\\theta= \\left( \\sqrt{\\alpha}x -\\frac{b}{2 \\sqrt{ \\alpha }} \\right)^{2}\\), temos\n\\[\\begin{eqnarray*}\n\\theta & = & \\left( \\sqrt{\\alpha} x - \\frac{b}{2 \\sqrt{ \\alpha }} \\right)^{2}\\nonumber\\\\\n       & = & \\left( \\frac{2 \\alpha x - b}{2 \\sqrt{ \\alpha }} \\right)^{2}\\nonumber\\\\\n       & = & \\frac{ \\left( x - \\frac{b}{ 2 \\alpha} \\right)^{2} }{ 4 \\alpha }\n\\end{eqnarray*}\\]\ne com \\(\\mu = \\frac{b}{2 \\alpha}\\) e \\(\\sigma^{2} = \\frac{1}{2 \\alpha}\\) chegamos em\n\\[\\begin{equation*}\n\\theta = \\frac{ \\left( x - \\mu \\right)^{2} }{ 2 \\sigma^{2} }\n\\end{equation*}\\]\ne assim ficamos com\n\\[\\begin{equation*}\nf(x)\\hspace{0.2cm}=\\hspace{0.2cm} \\beta \\hspace{0.2cm} exp \\left\\{ -  \\frac{ \\left( x - \\mu \\right)^{2} }{ 2 \\sigma^{2} } \\right\\}\n.\n\\end{equation*}\\]\nAgora precisamos que nossa \\(f(x)\\) integrada nos intervalos de menos infinito a mais infinito seja igual a \\(1\\), conforme Equação (Equation 3), ou seja,\n\\[\\begin{equation*}\n\\int_{- \\infty}^{+ \\infty} f(x) \\hspace{0.2cm} dx = 1\n,\n\\end{equation*}\\]\nVamos escrever \\(I\\) como\n\\[\nI = \\int_{- \\infty}^{+ \\infty}  \\beta \\hspace{0.2cm} exp \\left\\{ -  \\frac{ \\left( x - \\mu \\right)^{2} }{ 2 \\sigma^{2} } \\right\\} \\hspace{0.2cm} dx\n,\n\\tag{5}\\]\nque deve ser igual a \\(1\\). Para resolvermos esta integral, faremos uma mudança de variável, ou seja,\n\\[\nu \\hspace{0.2cm} = \\hspace{0.2cm} x \\hspace{0.2cm} - \\hspace{0.2cm} \\mu\n\\tag{6}\\]\nassim\n\\[\ndu \\hspace{0.2cm} = \\hspace{0.2cm} dx \\hspace{0.2cm}\n,\n\\tag{7}\\]\nficando com\n\\[\\begin{equation*}\nI = \\beta  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{ - \\frac{u^{2}}{ 2 \\sigma^{2}} } \\hspace{0.2cm} du \\hspace{0.2cm}\n.\n\\end{equation*}\\]\nComo\n\\[\\begin{equation*}\n\\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{ - \\gamma u^{2} } \\hspace{0.2cm} du = \\sqrt{ \\frac{ \\pi }{ \\gamma } } \\hspace{0.5cm} ,\n\\end{equation*}\\]\n(ver seção Section 3) temos\n\\[\\begin{equation*}\nI \\hspace{0.2cm} = \\hspace{0.2cm} \\beta \\hspace{0.2cm} \\sqrt{ 2 \\sigma^{2} \\pi }\n,\n\\end{equation*}\\]\ne como \\(I\\) deve ser igual a \\(1\\)\n\\[\\begin{equation*}\n\\beta \\hspace{0.2cm} \\sqrt{ 2 \\sigma^{2} \\pi } \\hspace{0.2cm} = \\hspace{0.2cm} 1\n,\n\\end{equation*}\\]\nde onde\n\\[\\begin{equation*}\n\\beta \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{1}{ \\sqrt{ 2 \\sigma^{2} \\pi }} \\hspace{0.2cm}\n.\n\\end{equation*}\\]\nDessa forma, temos abaixo a função densidade de probabilidade (\\(fdp\\)), Equação (Equation 1), a qual queríamos demonstrar, ou seja,\n\\[\\begin{equation*}\nf(x)= \\frac{1}{\\sqrt{2 \\pi \\sigma}} e^{- \\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm}\n.\n\\end{equation*}\\]\nAgora, resta ainda calcular a esperança e a variância desta \\(fdp\\), a fim de mostrar que\n\\[\n\\mu \\hspace{0.2cm}  = \\hspace{0.2cm}   E(X) \\hspace{0.2cm}  = \\hspace{0.2cm} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}  x \\hspace{0.2cm}  f(x) \\hspace{0.2cm}  dx \\hspace{0.2cm}\n\\tag{8}\\]\ne que\n\\[\n\\sigma^{2} \\hspace{0.2cm}  = \\hspace{0.2cm}   Var(X) \\hspace{0.2cm}  = \\hspace{0.2cm} E [ ( X - \\mu )^{2} ]      \\hspace{0.2cm}  = \\hspace{0.2cm}  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}  ( X - \\mu )^{2} \\hspace{0.2cm}  f(x) \\hspace{0.2cm}  dx \\hspace{0.2cm}.\n\\tag{9}\\]\nComeçando, então, pela definição da esperança matemática \\(E(X)\\) para a nossa \\(fdp\\) temos\n\\[\\begin{eqnarray*}\nE(X) & = & \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}  x \\hspace{0.2cm}  f(x) \\hspace{0.2cm}  dx\\nonumber\\\\\n     & = & \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}  \\frac{x}{\\sqrt{2 \\pi \\sigma^{2}}} e^{- \\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm} du\\nonumber\\\\\n     & = & \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} x   e^{- \\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\hspace{0.2cm}  du\\hspace{0.2cm}\n.\n\\end{eqnarray*}\\]\nPara resolvermos esta integral, faremos uma mudança de variável para \\(x\\), conforme Equações (Equation 6) e (Equation 7)), ficando com\n\\[\\begin{eqnarray*}\nE(X) & = & \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}(u + \\mu) \\hspace{0.2cm} e^{- \\frac{(u)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm}  \\hspace{0.2cm}  du \\hspace{0.2cm}\\nonumber\\\\\n     & = & \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\left[  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.1cm} u \\hspace{0.1cm} e^{- \\frac{(u)^{2}}{2 \\sigma^{2}}}\\hspace{0.1cm}  \\hspace{0.1cm}  du \\hspace{0.1cm}  + \\hspace{0.1cm} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.1cm} \\mu \\hspace{0.1cm} e^{- \\frac{(u)^{2}}{2 \\sigma^{2}}}\\hspace{0.1cm}  \\hspace{0.1cm}  du       \\right]\\nonumber\\\\\n\\end{eqnarray*}\\]\nem que a primeira integral do lado direito da igualdade acima é igual a zero (ver seção Section 4).\nEntão,\n\\[\\begin{equation*}\nE(X) \\hspace{0.2cm}  = \\hspace{0.2cm}\\frac{\\mu}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}  e^{- \\frac{(u)^{2}}{2 \\sigma^{2}}} \\hspace{0.2cm} du\\hspace{0.2cm} \\hspace{0.2cm}.\n\\end{equation*}\\]\nconforme seção Section 3. Dessa forma, temos que\n\\[\\begin{equation*}\nE(X) \\hspace{0.2cm}  = \\hspace{0.2cm}\\frac{\\mu}{\\sqrt{2 \\pi \\sigma^{2}}} \\hspace{0.2cm} \\sqrt{2 \\pi \\sigma^{2}} \\hspace{0.2cm} = \\hspace{0.2cm} \\mu\n\\hspace{0.2cm},\n\\end{equation*}\\]\nque é a média \\(\\mu\\), ou seja, vemos que a esperança da \\(fdp\\) estudada é\n\\[\nE(X) \\hspace{0.2cm}  = \\hspace{0.2cm} \\mu\n\\hspace{0.2cm},\n\\tag{10}\\]\nconforme queríamos demonstrar.\nContinuemos, agora, com o cálculo da variância \\(Var (X)\\) da nossa \\(fdp\\). Pela definição temos que \\[\\begin{eqnarray*}\nVar(X) &  = & E [ ( X - \\mu )^{2} ]\\nonumber\\\\\n       &  = &   \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}  ( x - \\mu )^{2} \\hspace{0.2cm}  f(x) \\hspace{0.2cm}  dx \\hspace{0.2cm}\\nonumber\\\\\n       &  = &  \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}(x - \\mu)^{2} \\hspace{0.2cm} e^{- \\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm}  \\hspace{0.2cm}  dx \\hspace{0.2cm}\n,\n\\end{eqnarray*}\\]\ne fazendo a substituição da variável \\(x\\) conforme Equações ((Equation 6)) e ((Equation 7)), ficamos com\n\\[\\begin{equation*}\nVar(X) \\hspace{0.2cm}  = \\hspace{0.2cm} \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}(u)^{2} \\hspace{0.2cm} e^{- \\frac{(u)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm}  \\hspace{0.2cm}  du\n\\hspace{0.2cm},\n\\end{equation*}\\]\nque pode ser resolvida por partes, conforme seção Section 5, para tornar-se\n\\[\nVar(X) \\hspace{0.2cm}  = \\hspace{0.2cm} \\sigma^{2}\n\\hspace{0.2cm},\n\\tag{11}\\]\nque é a variância da \\(fdp\\) estudada, conforme queríamos demonstar.\n\n\nIntegral A\nQueremos mostrar que a integral\n\\[\nI_{A} =  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{- \\lambda x^{2}}\\hspace{0.2cm}  \\hspace{0.2cm}  dx\n\\hspace{0.2cm},\n\\tag{12}\\]\nque é conhecida como gaussiana, é igual a \\(\\sqrt{\\frac{\\pi}{\\lambda}}\\). Esta integral também pode ser escrita como\n\\[\\begin{equation*}\nI_{A} =  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{- \\lambda y^{2}}\\hspace{0.2cm}  \\hspace{0.2cm}  dy\n\\hspace{0.2cm},\n\\end{equation*}\\]\nem que a variável \\(x\\) foi substituida por \\(y\\). Isto é possível, pois \\(x\\) e \\(y\\) são variáveis mudas, ou seja, o valor de \\(I_{A}\\) não depende destas variáveis. Assim, podemos fazer \\(I_{A}^{2}\\) para termos\n\\[\\begin{eqnarray*}\nI_{A}^{2} & = & \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{- \\lambda x^{2}}\\hspace{0.2cm}  \\hspace{0.2cm}  dx  \\hspace{0.3cm}    \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{- \\lambda y^{2}}\\hspace{0.2cm}  \\hspace{0.2cm}  dy\n\\hspace{0.2cm}\\\\\n    &=& \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{- \\lambda (x^{2} + y^{2})}\\hspace{0.2cm}dx \\hspace{0.2cm} dy \\hspace{0.2cm}\n.\n\\end{eqnarray*}\\]\nAgora, é preciso fazermos uma transformação de coordenadas, indo do sistema de coordenadas retangulares para o sistema de coordenadas polares. Um ponto \\(P\\) do plano é representado por \\(P(x, y)\\) num sistema de coordenadas retangulares ou por \\(P(r, \\theta)\\) num sistema de coordenadas polares. Quando conhecemos \\(x\\) e \\(y\\) podemos escrever \\(r\\) como \\(r^{2}=x^{2} +y^{2}\\) e fazermos o elemento de área \\(da = dx dy\\) ser \\(da = r dr d\\theta\\). Desta forma, quando os limites de integração \\(x\\) e \\(y\\) variarem de \\(- \\infty\\) a \\(+ \\infty\\) temos que \\(r\\) deve ir de \\(0\\) a \\(+ \\infty\\) e \\(\\theta\\) de \\(0\\) a \\(2 \\pi\\). Assim, a integral\n\\[\\begin{equation*}\nI_{A}^{2} =  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{- \\lambda (x^{2} + y^{2})}\\hspace{0.2cm}dx \\hspace{0.2cm} dy \\hspace{0.2cm}\n\\end{equation*}\\]\naqui, representada no sistema de coordenadas retangulares, é transformada em\n\\[\\begin{equation*}\nI_{A}^{2} =  \\int_{0}^{2 \\pi}   \\hspace{0.2cm} \\int_{0}^{+ \\infty}   \\hspace{0.2cm} r e^{- \\lambda r^{2}}\\hspace{0.2cm}dr \\hspace{0.2cm} d\\theta \\hspace{0.2cm}\n\\end{equation*}\\]\nque é sua representação em coordenadas polares. Então\n\\[\\begin{eqnarray*}\nI_{A}^{2} & = & \\int_{0}^{2 \\pi}  d\\theta \\hspace{0.2cm} \\int_{0}^{+ \\infty}   \\hspace{0.2cm} r e^{- \\lambda r^{2}}\\hspace{0.2cm}dr \\hspace{0.2cm}\\\\\n    & = & 2 \\pi \\hspace{0.2cm} \\int_{0}^{+ \\infty}   \\hspace{0.2cm} r e^{- \\lambda r^{2}}\\hspace{0.2cm}dr \\hspace{0.2cm}\n.\n\\end{eqnarray*}\\]\nPara resolvermos a integral em \\(r\\) fazemos \\(u = r^{2}\\) e \\(du = 2 r dr\\). Assim\n\\[\\begin{eqnarray*}\nI_{A}^{2} & = & 2 \\pi \\hspace{0.2cm} \\int_{0}^{+ \\infty}   \\hspace{0.2cm} \\frac{1}{2}\\hspace{0.2cm}  e^{- \\lambda u}\\hspace{0.2cm}du \\hspace{0.2cm}\\\\\n    & = & \\left[ - \\frac{\\pi}{\\lambda} \\hspace{0.2cm} e^{- \\lambda u}\\hspace{0.2cm} \\right]_{0}^{+ \\infty}\\\\\n    & = & - \\frac{\\pi}{\\lambda} \\left( \\frac{1}{e^{+ \\infty}} - \\frac{1}{e^{\\lambda (0)}} \\right)\\\\\n    & = & - \\frac{\\pi}{\\lambda} \\left( 0 - 1 \\right)\\\\\n    & = & \\frac{\\pi}{\\lambda}\n\\end{eqnarray*}\\]\ne finalmente, aplicando a raiz quadrada em ambos os lados da igualdade,\n\\[\nI_{A} = \\sqrt{\\frac{\\pi}{\\lambda}}\n\\tag{13}\\]\nconforme queríamos demonstrar.\n\n\nIntegral B\nOutro resultado que queremos demonstrar é\n\\[\nI_{B} =  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} x \\hspace{0.2cm} e^{- \\beta x^{2}}\\hspace{0.2cm}  \\hspace{0.2cm}  dx = 0\n\\hspace{0.2cm},\n\\tag{14}\\]\nPara isto, faremos a substituição \\(u = \\beta x^{2}\\) e \\(du = 2 \\beta x dx\\). Assim\n\\[\\begin{eqnarray*}\nI_{B} & = &  \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} \\frac{1}{2 \\beta} \\hspace{0.2cm} e^{-u}\\hspace{0.2cm}  \\hspace{0.2cm}  du\\\\\n      & = & \\frac{1}{2 \\beta} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} e^{-u}\\hspace{0.2cm} \\hspace{0.2cm} du\\\\\n      & = & \\frac{1}{2 \\beta} \\left[ - e^{-u}  \\right]_{- \\infty}^{+ \\infty}\\\\\n      & = & \\frac{1}{2 \\beta} \\left( - \\frac{1}{e^{+ \\infty}} + \\frac{1}{e^{- \\infty}}  \\right)\\\\\n      & = & \\frac{1}{2 \\beta} \\left( -0 + 0 \\right)\\\\\n      & = & 0\n\\end{eqnarray*}\\]\nconforme queríamos demonstrar.\n\n\nIntegral C\nSupondo\n\\[\nI_{C} \\hspace{0.2cm}  = \\hspace{0.2cm} \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm}(z)^{2} \\hspace{0.2cm} e^{- \\frac{(z)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm}  \\hspace{0.2cm}  dz\n\\hspace{0.2cm},\n\\tag{15}\\]\nqueremos demonstrar que \\(I_{C} = \\sigma^{2}\\). Resolveremos esta integral por partes, ou seja, usando a definição\n\\[\n\\int u dv = uv - \\int v du\n\\tag{16}\\]\ne fazendo\n\\[\\begin{equation*}\nI_{C} \\hspace{0.2cm}  = \\hspace{0.2cm} \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty}   \\hspace{0.2cm} \\underbrace{z}_{u}         \\underbrace{ z \\hspace{0.2cm} e^{- \\frac{(z)^{2}}{2 \\sigma^{2}}}\\hspace{0.2cm}  \\hspace{0.2cm}  dz}_{dv}\n\\hspace{0.2cm},\n\\end{equation*}\\]\ntemos, com isso, que \\(u=z\\), \\(du=dz\\), \\(dv= z \\hspace{0.2cm} e^{- \\frac{(z)^{2}}{2 \\sigma^{2}}} dz\\) e então \\(v= \\int z e^{-\\frac{z^{2}}{2 \\sigma^{2}}} dz\\). Esta última integral, para encontrarmos \\(v\\), pode ser resolvida com \\(t=\\frac{z^{2}}{2 \\sigma^{2}}\\) e \\(dt= \\frac{z}{\\sigma^{2}} dz\\). Assim, fazendo estas substituições,\n\\[\\begin{eqnarray*}\nv & = & \\sigma^{2} \\int e^{-t} dt\\\\\n  & = & - \\sigma^{2}  e^{-t}\n,\n\\end{eqnarray*}\\]\ne como fizemos \\(t=\\frac{z^{2}}{2 \\sigma^{2}}\\), \\(v\\) finalmente fica \\(v= - \\sigma^{2} e^{-\\frac{z^{2}}{2 \\sigma^{2}}}\\). Com isto,\n\\[\\begin{eqnarray*}\nI_{C}  & = & \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\left[ - z \\sigma^{2} e^{- \\frac{z^{2}}{2 \\sigma^{2}}}   \\right]_{-\\infty}^{+\\infty} - \\int_{- \\infty}^{+ \\infty} \\left( - \\sigma^{2} e^{-\\frac{z^{2}}{2 \\sigma^{2}}}   \\right) dz\\\\\n       & = & \\frac{\\sigma^{2}}{\\sqrt{2 \\pi \\sigma^{2}}} \\int_{- \\infty}^{+ \\infty} e^{-\\frac{z^{2}}{2 \\sigma^{2}}} \\hspace{0.2cm} dz\\\\\n        & = & \\frac{\\sigma^{2}}{\\sqrt{2 \\pi \\sigma^{2}}} \\sqrt{2 \\pi \\sigma^{2}}\\\\\n        & = & \\sigma^{2}\n.\n\\end{eqnarray*}\\]\n\n\n\n\n\n\nFootnotes\n\n\nCaso encontre erros, queira fazer comentários, ou trocar uma ideia sobre o artigo, por favor, me escreva: omarcnpereiraead@gmail.com↩︎"
  },
  {
    "objectID": "lista.html#distribuição-normal",
    "href": "lista.html#distribuição-normal",
    "title": "Lista de exercícios",
    "section": "Distribuição Normal",
    "text": "Distribuição Normal\n\nSuponha que, numa dada população, o QI (Quociente de Inteligência) siga uma distribuição Normal com média 105 e variância 49. Calcule:\n\n\na probabilidade de encontrarmos nessa população indivíduos com QI acima de 115.\na quantidade de indivíduos que tem QI entre 90 e 100, dado que esta população é composta por 10000 sujeitos.\no valor mínimo de QI para que um indivíduo seja considerado super inteligente (considere que apenas 1% da população seja super inteligente).\n\n\nAs notas finais da disciplina de Estatística se distribuiem normalmente com méia 6.75 e variância 9. Se o valor para a aprovação é 6.00, responda:\n\n\nqual a probabilidade de um aluno ser aprovado na disciplina?\nse a sala tem 40 alunos, quantos estarão aprovados?\nqual a probabilidade de um aluno ser aprovado com média final maior que 8.00?\n\n\nSe uma dada espécie de peixe vive em média 550 dias (desvio padrão de 80 dias) em um aquário, responda:\n\n\nqual a probabilidade de um peixe viver mais que 700 dias?\nsabendo que 25% dos peixes dessa população morrem antes de atingirem a fase reprodutiva, qual o tempo de vida de um peixe para atingir essa fase?"
  }
]